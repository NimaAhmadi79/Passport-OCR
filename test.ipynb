{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "from basic_functions import Basic\n",
    "from extractchar_functions import Extract\n",
    "from getfiles_functions import Getfiles\n",
    "from postprocess_functions import Postprocess\n",
    "from preprocess_functions import Preprocess\n",
    "from subsidiary_functions import Subsidiary\n",
    "from collections import OrderedDict\n",
    "\n",
    "extract=Extract()\n",
    "getfiles=Getfiles()\n",
    "basic=Basic()\n",
    "post=Postprocess()\n",
    "pre=Preprocess()\n",
    "sub=Subsidiary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_barcodes(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #perform theresholding \n",
    "    thresholded_img=pre.thresholding(gray,120)\n",
    "\n",
    "    # Use ZBar to detect and decode barcodes\n",
    "    barcodes = decode(thresholded_img)\n",
    "\n",
    "    # Print the barcode data\n",
    "    for barcode in barcodes:\n",
    "        data = barcode.data.decode(\"utf-8\")\n",
    "        print(\"Barcode data:\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcode data: 0254010164\n"
     ]
    }
   ],
   "source": [
    "image_path=\"images/Binder2_Page_4.jpg\"\n",
    "scan_barcodes(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55617.1 55617.1\n"
     ]
    }
   ],
   "source": [
    "bozorg=cv2.imread(\"ax bozorg.jpg\",0)\n",
    "kocholo=cv2.imread(\"ax kocholoe.jpg\",0)\n",
    "\n",
    "quality_bozorg=pre.amount_of_quality(bozorg)\n",
    "quality_kocholoe=pre.amount_of_quality(kocholo)\n",
    "\n",
    "print(quality_bozorg,quality_kocholoe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image and the template image in color format (BGR)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the loaded color images to grayscale images\n",
    "img= cv2.cvtColor(raw_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(x, y, width, height):\n",
    "    # Load the image\n",
    "    raw_img=cv2.imread(\"images/passport1.PNG\",cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Create a mask of the same size as the image\n",
    "    mask = np.zeros_like(raw_img)*255\n",
    "\n",
    "    # Set the specified region within the mask to white\n",
    "    mask[y:y+height, x:x+width] = 0\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    masked_image = cv2.bitwise_and(raw_img, mask)\n",
    "\n",
    "    # Display the masked image\n",
    "    cv2.imshow(\"Masked Image\", masked_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage: mask a specific region (100, 100) - (200, 200) to black\n",
    "\n",
    "x, y, width, height = 500, 20, 100, 100\n",
    "mask_image_to_black( x, y, width, height)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revrese(img):\n",
    "    #Reverse the colors of a given grayscale image.\n",
    "\n",
    "    # Get the number of rows and columns in the input image\n",
    "    row ,column=img.shape\n",
    "    # Create an image filled with 255 (white) of the same size as the input image\n",
    "    image_of_255=np.ones((row, column),dtype=np.uint8)*255\n",
    "\n",
    "    # Subtract the input image from the all-white image to reverse the colors\n",
    "    # The cv2.subtract function subtracts the pixel values element-wise\n",
    "    reversed_image=cv2.subtract(image_of_255, img)\n",
    "    \n",
    "    return reversed_image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(img):\n",
    "    #Perform binary thresholding on a given grayscale image.\n",
    "\n",
    "    # Define the threshold value (pixel intensity value) to be used for thresholding\n",
    "    threshold_value =180\n",
    "    # max=np.max(reversed_image)\n",
    "    # min=np.min(reversed_image)\n",
    "    \n",
    "    # Apply binary thresholding to the input image\n",
    "    _, thresholded_image = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return thresholded_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    #perform normalization and transfer the amount of each pixel between 0 abd 1\n",
    "    normalized_img = cv2.normalize(img, None, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    # cv2.imshow(\"img_normalized\",normalized_img )\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return normalized_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thresholding on summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh(array,thresh):\n",
    "    # Manual function to perform thersholidng on an array\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        if array[i]>thresh:\n",
    "            array[i]=1\n",
    "        else:\n",
    "            array[i]=0\n",
    "    return array            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "        # fig = plt.figure()\n",
    "        # ax = fig.add_subplot(111, projection='3d')\n",
    "        # x_range = np.arange(result.shape[1])\n",
    "        # y_range = np.arange(result.shape[0])\n",
    "        # X, Y = np.meshgrid(x_range, y_range)\n",
    "        # ax.plot_surface(X, Y, result, cmap='jet')\n",
    "        # ax.set_title('Matching Result (3D)')\n",
    "        # ax.set_xlabel('X')\n",
    "        # ax.set_ylabel('Y')\n",
    "        # ax.set_zlabel('Matching Score')\n",
    "        # ax.view_init(elev=45, azim=70)\n",
    "        # mappable = ax.plot_surface(X, Y, result, cmap='jet')\n",
    "        # fig.colorbar(mappable, ax=ax, shrink=0.6)\n",
    "        # plt.show()\n",
    "\n",
    "        ## copy_img = cv2.circle(copy_img,pt1 , 0, (0,0,255), 10)\n",
    "        #cv2.rectangle(normaled_img, pt1,pt2 , (255, 0, 1), 2)\n",
    "# #############################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def templatematching(image,template):\n",
    "    #Perform template matching on a given image using a specified template    \n",
    "\n",
    "    # Get the height and width of the template image\n",
    "    template_height,template_width = template.shape\n",
    "\n",
    "    # Get the height and width of the input imag\n",
    "    image_height,image_width=image.shape\n",
    "\n",
    "    # Define the list of template matching methods to use\n",
    "    methods=[cv2.TM_CCOEFF]##,cv2.TM_CCOEFF_NORMED,cv2.TM_CCORR,cv2.TM_CCORR_NORMED,cv2.TM_SQDIFF,cv2.TM_SQDIFF_NORMED]\n",
    "\n",
    "    # Make a copy of the input image\n",
    "    copy_img=image.copy()\n",
    "\n",
    "    for method in methods:\n",
    "\n",
    "        # Perform template matching using the current method\n",
    "        result=cv2.matchTemplate(copy_img,template,method)\n",
    "        \n",
    "        # Find the location of the best match in the result image\n",
    "        _,_,min_loc,max_loc=cv2.minMaxLoc(result)\n",
    "\n",
    "        # Determine the location based on the method used\n",
    "        if method in [cv2.TM_SQDIFF , cv2.TM_SQDIFF_NORMED]:\n",
    "            location=min_loc\n",
    "        else:\n",
    "            location=max_loc\n",
    "\n",
    "         # Calculate the coordinates of the top-right the matched region and \n",
    "         # #The bottom right corner of the original photo is aligned with the bottom right corner of the photo\n",
    "        pt1=(location[0]+template_width,location[1])\n",
    "        pt2=(image_width,location[1]+template_height)\n",
    "        \n",
    "    return(pt1,pt2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summation(array):\n",
    "    #perform vertical summation \n",
    "\n",
    "    h,w=array.shape\n",
    "    #create array for summation of each column\n",
    "    sum_array=np.zeros(w)\n",
    "    for column in range(w):\n",
    "        temp=0\n",
    "        for row in range(h):              \n",
    "            temp=temp+array[row,column]\n",
    "        sum_array[column]=temp   \n",
    "         \n",
    "    return sum_array\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finde cut index temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cut_index_temp(f_index,derivative,cut_index_arr):\n",
    "\n",
    "#finde end of charecter and add first charecter postion and end charecter postion in cut index array\n",
    "    for j in range(f_index+1,len(derivative)):\n",
    "        if(derivative[j]==0):\n",
    "            for u in range(1,1000):\n",
    "                if(derivative[u+j]==0):\n",
    "                    pass\n",
    "                else:\n",
    "                    if(u>0):\n",
    "                        cut_index_arr.append(f_index)\n",
    "                        cut_index_arr.append(j+u)\n",
    "                    break\n",
    "            break  \n",
    "    \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find cut index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cut_index(derivative,cut_index_arr):\n",
    "\n",
    "    #Find the indexs that are most likely the starting and ending points of the characters\n",
    "\n",
    "    #Define help To count the number of consecutive zeros in an derivative array.\n",
    "    help=0 \n",
    "    for i in range(len(derivative)):\n",
    "        if(help>30):\n",
    "            break\n",
    "        if(derivative[i]==0):\n",
    "            help=help+1\n",
    "        if(derivative[i]!=0):\n",
    "            help=0\n",
    "\n",
    "        # If derivative[i] has a value grater that 0 after 0 or -0.5 it means that we have raise in summation array and it means this is the start of a charecter  \n",
    "        if (derivative[i]==0 or derivative[i]==-0.5) and derivative[i+1]>0:\n",
    "            find_cut_index_temp(i,derivative,cut_index_arr)\n",
    "\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(original_image,target_height,target_width):\n",
    "    height, width = original_image.shape\n",
    "    pad_height = max(target_height - height, 0)\n",
    "    pad_width = max(target_width - width, 0)\n",
    "    top_pad = pad_height // 2\n",
    "    bottom_pad = pad_height - top_pad\n",
    "    left_pad = pad_width // 2\n",
    "    right_pad = pad_width - left_pad\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "    original_image, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=0)\n",
    "    scaled_image = 255 * padded_image\n",
    "    scaled_image = np.clip(scaled_image, 0, 255)\n",
    "    uint8_image = scaled_image.astype(np.uint8)\n",
    "    \n",
    "    return uint8_image\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_image_quality(image_path, output_path, compression_quality):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Get the file extension of the input image\n",
    "    file_extension = image_path.split('.')[-1]\n",
    "\n",
    "    # Parameters for saving the image with compression quality (for JPEG format)\n",
    "    if file_extension.lower() in ['jpg', 'jpeg']:\n",
    "        compression_params = [cv2.IMWRITE_JPEG_QUALITY, compression_quality]\n",
    "\n",
    "        # Save the image with compression quality\n",
    "        cv2.imwrite(output_path, image, compression_params)\n",
    "\n",
    "    # For other formats like PNG, simply save the image without compression quality adjustment\n",
    "    else:\n",
    "        cv2.imwrite(output_path, image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amount_of_quality(image):\n",
    "\n",
    "    #calculate image quality \n",
    "\n",
    "    # Check if the image is in grayscale format\n",
    "    try:\n",
    "        if image.mode != \"L\":\n",
    "            raise ValueError(\"The input image should be in grayscale format.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error: Unable to open the image - {e}\")   \n",
    "    \n",
    "    #Convert iamge forat to unit8\n",
    "    image=image.astype(np.uint8)\n",
    "\n",
    "    #Define a laplacian window \n",
    "    window=np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])\n",
    "\n",
    "    #Get Conv2D from image with laplacian window detecte edges\n",
    "    result = cv2.filter2D(image, -1,window)\n",
    "\n",
    "    #Normalization because if we dont do that after summation value of each index will be very larg\n",
    "    normalized_result = cv2.normalize(result, None, 0, 1.0,cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    #Get hight and width of normalized_result\n",
    "    row ,column=normalized_result.shape\n",
    "\n",
    "    #Get summation of each row\n",
    "    sum=0\n",
    "    sum_of_row_array=[]\n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            sum=sum+normalized_result[i][j]\n",
    "\n",
    "        sum_of_row_array.append(sum)\n",
    "        sum=0    \n",
    "\n",
    "    #Round numbers of sum_of_row_array to 1 decimal places\n",
    "    sum_of_row_array=np.round(sum_of_row_array, 1)\n",
    "\n",
    "    #Get summation of sum_of_row_array\n",
    "    sum=0\n",
    "    for i in range(len(sum_of_row_array)):\n",
    "        sum=sum+sum_of_row_array[i]  \n",
    "\n",
    "    #Round numbers to 1 decimal\n",
    "    sum=np.round(sum,1)  \n",
    "    return sum    \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#perform template matching on img with template\n",
    "pt1,pt2=templatematching(img,template)\n",
    "\n",
    "#Get copy from orginal image\n",
    "copy_image=img.copy()\n",
    "\n",
    "#reverse value of each pixel \n",
    "reversed_img=revrese(copy_image)\n",
    "\n",
    "#perform thresholding on reversed image\n",
    "thresholded_img=thresholding(reversed_img)\n",
    "\n",
    "#normalize image\n",
    "normaled_img=normalize(thresholded_img)\n",
    "\n",
    "#Rectabgle front of matched region\n",
    "rectangled_image = normaled_img[pt1[1]:pt2[1], pt1[0]:pt2[0]]\n",
    "\n",
    "#Get vertical summation form rectangled section\n",
    "sum_arr=summation(rectangled_image)\n",
    "\n",
    "#Get copy from sum_arr\n",
    "copy_sum_arr=sum_arr.copy()\n",
    "\n",
    "#Set every index to 1 that has value grater that 1 and 0 if less than 1 \n",
    "sum_arr=thresh(sum_arr,1)\n",
    "\n",
    "# cv2.rectangle(copy_img, location, pt2, (0, 0, 255), 1)\n",
    "cv2.imshow(\"after matching\",rectangled_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Define cut_index_arr for save the start and ending postion of each charecter\n",
    "cut_index_arr=[]\n",
    "\n",
    "#Get derivative from sum_arr\n",
    "derivative = np.gradient(sum_arr, 1)\n",
    "\n",
    "#Find the position of start and ending postion of each charecter\n",
    "find_cut_index(derivative,cut_index_arr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saveing charecter from rectangled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rec_height,rec_width=rectangled_image.shape\n",
    "\n",
    "temp_image=rectangled_image.copy()\n",
    "# for i in range(len(cut_index_arr)):\n",
    "\n",
    "#      cv2.line(temp_image, (cut_index_arr[i], 0), (cut_index_arr[i], hh - 1), (255, 255, 0), 1)\n",
    "image_of_character=[]\n",
    "for i in range(0,len(cut_index_arr)):\n",
    "    if(i%2==0):\n",
    "        char = rectangled_image[1:rec_height,cut_index_arr[i]:cut_index_arr[i+1]]\n",
    "        # cv2.imshow('character image',char)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows() \n",
    "        image_of_character.append(char)\n",
    "        trasnformed_char=char*255\n",
    "        filename = f\"sample{i//2 + 1}.jpg\"\n",
    "        cv2.imwrite(\"fathers name charecter/\"+filename, trasnformed_char)\n",
    "\n",
    "       \n",
    "cv2.imshow('orginal', rectangled_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "\n",
    "# hh,ww=rectangled_image.shape\n",
    "# for i in range(len(array_of_cut)):\n",
    "\n",
    "#     #cv2.line(rectangled_image, (array_of_cut[i], 0), (array_of_cut[i], hh - 1), (255, 255, 0), 1)\n",
    "\n",
    "    \n",
    "# cv2.imshow('Image with Vertical Line', rectangled_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecte charecter with template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_template=cv2.imread(\"fathers name charecter/sample3.jpg\",cv2.IMREAD_COLOR)\n",
    "char_template_grey= cv2.cvtColor(char_template, cv2.COLOR_BGR2GRAY)\n",
    "thresholded_char_template=thresholding(char_template_grey)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#char_template=char_template.astype(np.float32)\n",
    "# reversed_char_template=revrese(char_template)\n",
    "# thresholded_char_template=thresholding(reversed_char_template)\n",
    "# normaled_char_template=normalize(thresholded_char_template)\n",
    "\n",
    "\n",
    "padded_charecter=[]\n",
    "for i in range(len(image_of_character)):\n",
    "      padded_charecter.append(padding(image_of_character[i],60,60))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# cv2.imshow('test1',image_of_character[0] )\n",
    "     \n",
    "\n",
    "best_match_val = None\n",
    "best_match_char = None\n",
    "for i in range(len(padded_charecter)):\n",
    "    new_result=cv2.matchTemplate(padded_charecter[i],thresholded_char_template,cv2.TM_CCOEFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(new_result)\n",
    "    if best_match_val is None or max_val > best_match_val:\n",
    "            best_match_val = max_val\n",
    "            best_match_char=i\n",
    "\n",
    "\n",
    "cv2.imshow('answer', padded_charecter[best_match_char])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)                # the first figure\n",
    "plt.subplot(211)             # the first subplot in the first figure\n",
    "plt.plot([1, 2, 3])\n",
    "plt.subplot(212)             # the second subplot in the first figure\n",
    "plt.plot([4, 5, 6])\n",
    "plt.show()\n",
    "# plt.figure(2)                # a second figure\n",
    "# plt.plot([4, 5, 6])          # creates a subplot(111) by default\n",
    "\n",
    "# plt.figure(1)                # figure 1 current; subplot(212) still current\n",
    "# plt.subplot(211)             # make subplot(211) in figure1 current\n",
    "# plt.title('Easy as 1, 2, 3') # subplot 211 title\n",
    "\n",
    "\n",
    "# x = np.arange(len(sum_arr))\n",
    "# plt.plot(x, sum_arr)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('plot')\n",
    "# plt.show()\n",
    "# x = np.arange(len(copy_array))\n",
    "# plt.plot(x, copy_array)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('plot')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_text_extraction_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten the output and add a Dense layer for classification\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification (text or not text)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Input shape: (image_height, image_width, num_channels)\n",
    "input_shape = (128, 128, 3)  # Modify according to your image size and channels\n",
    "text_extraction_model = create_text_extraction_model(input_shape)\n",
    "\n",
    "\n",
    "text_extraction_model.compile(optimizer='adam',\n",
    "                             loss='binary_crossentropy',\n",
    "                             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "text_extraction_model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the image (resize and normalize)\n",
    "image = preprocess_image(image)  # Implement the preprocess_image function according to your needs\n",
    "\n",
    "# Convert the image to a batch of size 1\n",
    "image_batch = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = text_extraction_model.predict(image_batch)\n",
    "\n",
    "# The prediction will be a value between 0 and 1, where 0 represents \"no text\" and 1 represents \"text.\"\n",
    "# You can set a threshold to decide if the image contains text or not.\n",
    "if prediction[0][0] >= 0.5:\n",
    "    print(\"The image contains text.\")\n",
    "else:\n",
    "    print(\"The image does not contain text.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "okernel",
   "language": "python",
   "name": "okernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27dce945bb2da940a5b3e3764ba67512b0d4323c270d398d6a5469083993861b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
